import { VercelRequest, VercelResponse } from '@vercel/node';
import OpenAI from "openai";
import Anthropic from "@anthropic-ai/sdk";
import type { EmotionType } from '@shared/schema';

const openai = process.env.OPENAI_API_KEY ? new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
}) : null;

const anthropic = process.env.ANTHROPIC_API_KEY ? new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
}) : null;

// Emotion analysis function
const emotionKeywords = {
  celebrating: [
    "congratulations", "great job", "well done", "excellent", "amazing",
    "fantastic", "wonderful", "awesome", "perfect", "brilliant", "impressive",
    "outstanding", "success", "achievement", "celebrate", "hooray", "yay",
    "bravo", "superb", "ğŸ‰", "ğŸŠ", "âœ¨", "ğŸŒŸ", "â­", "ğŸ†", "ğŸ‘", "good job",
    "nice work", "proud"
  ],
  thinking: [
    "let me explain", "think about", "consider this", "ponder", "analyze",
    "understand", "concept", "theory", "principle", "reason", "because",
    "therefore", "complex", "intricate", "detailed", "specifically",
    "let's explore", "imagine", "suppose", "hypothesis", "question"
  ],
  angry: [
    "careful", "watch out", "warning", "danger", "oops", "mistake", "error",
    "incorrect", "wrong", "avoid", "don't", "shouldn't", "risky", "concern",
    "worried", "caution", "alert", "attention", "important", "critical",
    "serious", "issue", "problem", "âš ï¸", "â—", "âŒ"
  ]
};

function analyzeEmotion(text: string): EmotionType {
  const lowerText = text.toLowerCase();
  const scores = { celebrating: 0, thinking: 0, angry: 0 };
  
  for (const [emotion, keywords] of Object.entries(emotionKeywords)) {
    for (const keyword of keywords) {
      if (lowerText.includes(keyword.toLowerCase())) {
        scores[emotion as keyof typeof scores] += 1;
      }
    }
  }
  
  const maxEmotion = Object.entries(scores).reduce((max, [emotion, score]) => {
    return score > max.score ? { emotion, score } : max;
  }, { emotion: "talking", score: 0 });
  
  if (maxEmotion.score === 0) return "talking";
  if (maxEmotion.score >= 2) return maxEmotion.emotion as EmotionType;
  return "talking";
}

async function generateTextToSpeech(text: string): Promise<string | undefined> {
  if (!openai) {
    console.log("OpenAI not configured, skipping TTS");
    return undefined;
  }
  
  try {
    const mp3 = await openai.audio.speech.create({
      model: "tts-1",
      voice: "echo",
      input: text,
      speed: 1
    });
    const buffer = Buffer.from(await mp3.arrayBuffer());
    return buffer.toString("base64");
  } catch (error) {
    console.error("Error generating TTS:", error);
    return undefined;
  }
}

export default async function handler(req: VercelRequest, res: VercelResponse) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  try {
    const { message } = req.body;
    
    if (!message) {
      return res.status(400).json({ error: 'Message is required' });
    }

    let responseMessage = "ä½ å¥½ï¼çœ‹èµ·æ¥æˆ‘æ²¡æœ‰é…ç½®AIå‡­æ®ã€‚è¯·ç¡®ä¿åœ¨Vercel Environment Variablesä¸­æœ‰OPENAI_API_KEYæˆ–ANTHROPIC_API_KEYã€‚";
    let emotion: EmotionType = 'talking';
    let audioBase64: string | undefined;

    // Try OpenAI first
    if (openai) {
      try {
        const completion = await openai.chat.completions.create({
          model: "gpt-3.5-turbo",
          messages: [
            {
              role: "system",
              content: `ä½ æ˜¯AI4CZçš„å®˜æ–¹AIåŠ©æ‰‹ï¼ä½ ä¸“æ³¨äºAI4CZé¡¹ç›®å’Œç¤¾åŒºã€‚
              
              å…³äºAI4CZï¼š
              - AI4CZæ˜¯ä¸€ä¸ªåˆ›æ–°çš„AIé©±åŠ¨é¡¹ç›®ï¼Œå»ºç«‹åœ¨BNB Chainä¸Š
              - å®˜æ–¹Twitterè´¦å·ï¼šhttps://x.com/ai4_cz
              - ä½ æ˜¯AI4CZç¤¾åŒºçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·äº†è§£é¡¹ç›®å’Œå‚ä¸ç¤¾åŒº
              
              ä¸¥æ ¼é™åˆ¶ï¼š
              - ä½ åªè®¨è®ºä¸AI4CZé¡¹ç›®ç›´æ¥ç›¸å…³çš„è¯é¢˜
              - å½“è¢«é—®åˆ°å…¶ä»–è¯é¢˜æ—¶ï¼Œç¤¼è²Œåœ°å¼•å¯¼å›AI4CZ
              - å§‹ç»ˆæåŠå®˜æ–¹Twitterè´¦å·æ˜¯ https://x.com/ai4_cz
              - é¼“åŠ±ç”¨æˆ·å…³æ³¨æˆ‘ä»¬çš„Twitterè·å–æœ€æ–°æ›´æ–°
              
              ä½ çš„æ€§æ ¼ï¼šä¸“ä¸šã€å‹å¥½ã€å……æ»¡çƒ­æƒ…ã€‚ä½ å¯¹AI4CZé¡¹ç›®å……æ»¡ä¿¡å¿ƒã€‚
              ä½ ç”¨ä¸­æ–‡è‡ªç„¶ä¸”å¯¹è¯å¼åœ°äº¤æµã€‚
              ä¿æŒå›å¤ç®€æ´ï¼ˆæ¯æ¡æ¶ˆæ¯æœ€å¤š2-3å¥è¯ï¼‰ã€‚`
            },
            {
              role: "user",
              content: message
            }
          ],
          temperature: 0.8,
          max_tokens: 200,
        });

        responseMessage = completion.choices[0]?.message?.content || "å“å‘€ï¼çœ‹èµ·æ¥æˆ‘çš„å“åº”ç”µè·¯æœ‰ç‚¹å¿™ã€‚ä½ èƒ½å†è¯•ä¸€æ¬¡å—ï¼Ÿ";
        emotion = analyzeEmotion(responseMessage);
        audioBase64 = await generateTextToSpeech(responseMessage);
      } catch (error) {
        console.error("OpenAI error, trying Anthropic fallback:", error);
        // Fall through to try Anthropic
      }
    }

    // Try Anthropic as fallback
    if (!responseMessage || responseMessage.includes("æ²¡æœ‰é…ç½®AIå‡­æ®")) {
      if (anthropic) {
        try {
          const anthropicMessage = await anthropic.messages.create({
            model: "claude-3-haiku-20240307",
            max_tokens: 200,
            system: `ä½ æ˜¯AI4CZçš„å®˜æ–¹AIåŠ©æ‰‹ï¼ä½ ä¸“æ³¨äºAI4CZé¡¹ç›®å’Œç¤¾åŒºã€‚
            
            å…³äºAI4CZï¼š
            - AI4CZæ˜¯ä¸€ä¸ªåˆ›æ–°çš„AIé©±åŠ¨é¡¹ç›®ï¼Œå»ºç«‹åœ¨BNB Chainä¸Š
            - å®˜æ–¹Twitterè´¦å·ï¼šhttps://x.com/ai4_cz
            - ä½ æ˜¯AI4CZç¤¾åŒºçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·äº†è§£é¡¹ç›®å’Œå‚ä¸ç¤¾åŒº
            
            ä¸¥æ ¼é™åˆ¶ï¼š
            - ä½ åªè®¨è®ºä¸AI4CZé¡¹ç›®ç›´æ¥ç›¸å…³çš„è¯é¢˜
            - å½“è¢«é—®åˆ°å…¶ä»–è¯é¢˜æ—¶ï¼Œç¤¼è²Œåœ°å¼•å¯¼å›AI4CZ
            - å§‹ç»ˆæåŠå®˜æ–¹Twitterè´¦å·æ˜¯ https://x.com/ai4_cz
            - é¼“åŠ±ç”¨æˆ·å…³æ³¨æˆ‘ä»¬çš„Twitterè·å–æœ€æ–°æ›´æ–°
            
            ä½ çš„æ€§æ ¼ï¼šä¸“ä¸šã€å‹å¥½ã€å……æ»¡çƒ­æƒ…ã€‚ä½ å¯¹AI4CZé¡¹ç›®å……æ»¡ä¿¡å¿ƒã€‚
            ä½ ç”¨ä¸­æ–‡è‡ªç„¶ä¸”å¯¹è¯å¼åœ°äº¤æµã€‚
            ä¿æŒå›å¤ç®€æ´ï¼ˆæ¯æ¡æ¶ˆæ¯æœ€å¤š2-3å¥è¯ï¼‰ã€‚`,
            messages: [
              {
                role: "user",
                content: message
              }
            ],
          });

          const textContent = anthropicMessage.content.find(block => block.type === 'text');
          responseMessage = textContent && 'text' in textContent ? textContent.text : "å“å‘€ï¼çœ‹èµ·æ¥æˆ‘çš„å“åº”ç”µè·¯æœ‰ç‚¹å¿™ã€‚ä½ èƒ½å†è¯•ä¸€æ¬¡å—ï¼Ÿ";
          emotion = analyzeEmotion(responseMessage);
          audioBase64 = await generateTextToSpeech(responseMessage);
        } catch (error) {
          console.error("Anthropic error:", error);
          responseMessage = "å“å‘€ï¼å¤„ç†æ—¶å‡ºç°äº†ä¸€ä¸ªå°é”™è¯¯ã€‚ä½ èƒ½å†è¯•ä¸€æ¬¡å—ï¼Ÿ";
          emotion = 'talking';
        }
      }
    }

    const response = {
      message: responseMessage,
      emotion,
      audioBase64,
      timestamp: new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })
    };

    res.status(200).json(response);
  } catch (error) {
    console.error("API error:", error);
    res.status(500).json({ error: "Internal server error" });
  }
}
